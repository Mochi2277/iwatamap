import streamlit as st
import pandas as pd
import numpy as np
import json
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.feature_extraction.text import TfidfVectorizer

# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
with open("embeddings.json", "r", encoding="utf-8") as f:
    data = json.load(f)

df = pd.DataFrame(data)

# --- Streamlit UI ---
st.title("ç£ç”°å¸‚ãŠã™ã™ã‚ã‚¹ãƒãƒƒãƒˆæ¤œç´¢ï¼ˆFastTextãƒ™ãƒ¼ã‚¹ï¼‰")

query = st.text_input("ã©ã‚“ãªå ´æ‰€ã‚’æ¢ã—ã¦ã„ã¾ã™ã‹ï¼Ÿï¼ˆä¾‹ï¼šè‡ªç„¶ãŒå¤šã„ã‚«ãƒ•ã‚§ï¼‰")

def get_query_vector(query_text, model_dim=300):
    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å˜èªã«åˆ†å‰²ï¼ˆã‹ãªã‚Šç°¡æ˜“çš„ï¼‰
    words = query_text.split()
    vectors = []
    for word in words:
        for row in df["vector"]:
            if word in row:  # ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ï¼šã™ã§ã«åŸ‹ã‚è¾¼ã¾ã‚Œã¦ã‚‹ã®ã§ã“ã“ã§ã¯ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«
                vectors.append(row[word])
    if not vectors:
        return np.zeros((1, model_dim))
    return np.mean(vectors, axis=0).reshape(1, -1)

if query:
    # ã‚¯ã‚¨ãƒªãƒ™ã‚¯ãƒˆãƒ«ï¼ˆç°¡æ˜“çš„ã«TF-IDFã§ã‚‚OKï¼‰
    vectorizer = TfidfVectorizer()
    all_texts = [x["description"] for x in data]
    vectorizer.fit(all_texts)
    query_vec = vectorizer.transform([query])

    doc_vecs = vectorizer.transform(all_texts)

    similarities = cosine_similarity(query_vec, doc_vecs)[0]
    df["similarity"] = similarities
    top_results = df.sort_values("similarity", ascending=False).head(5)
else:
    top_results = df.head(5)

# --- æ¤œç´¢çµæœè¡¨ç¤ºï¼ˆã‚«ãƒ¼ãƒ‰å‹ï¼‰ ---
st.subheader("ğŸ” ãŠã™ã™ã‚ã‚¹ãƒãƒƒãƒˆ")

for _, row in top_results.iterrows():
    st.markdown(f"""
    <div style="border:1px solid #ccc; border-radius:8px; padding:12px; margin-bottom:16px; background-color:#f9f9f9;">
        <h4>{row['place_name']}</h4>
        <p><strong>è©•ä¾¡:</strong> â­ï¸ {row['rating']}ï¼ˆ{row['user_ratings_total']}ä»¶ï¼‰</p>
        <p><strong>èª¬æ˜:</strong> {row['description']}</p>
        <p><strong>ä½æ‰€:</strong> {row['formatted_address']}</p>
        <a href="{row['google_map_url']}" target="_blank">ğŸ“ Googleãƒãƒƒãƒ—ã§é–‹ã</a>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("")

# --- çµæœã‚’foliumãƒãƒƒãƒ—ã§è¡¨ç¤ºã™ã‚‹ã®ã‚‚å¯èƒ½ï¼ˆå¿…è¦ãªã‚‰è¿½è¨˜ï¼‰ ---
